__author__ = "Justin Ribeiro <justin@justinribeiro.com>"

import re


# generated via ./utilities/getbots.py
def aiBots():
    pattern = "(?:%s)" % "|".join(
        [
            "AddSearchBot",
            "AI2Bot",
            "AI2Bot-DeepResearchEval",
            "Ai2Bot-Dolma",
            "aiHitBot",
            "amazon-kendra",
            "Amazonbot",
            "AmazonBuyForMe",
            "Andibot",
            "Anomura",
            "anthropic-ai",
            "Applebot",
            "Applebot-Extended",
            "atlassian-bot",
            "Awario",
            "bedrockbot",
            "bigsur.ai",
            "Bravebot",
            "Brightbot/ 1.0",
            "BuddyBot",
            "Bytespider",
            "CCBot",
            "Channel3Bot",
            "ChatGLM-Spider",
            "ChatGPT/ Agent",
            "ChatGPT-User",
            "Claude-SearchBot",
            "Claude-User",
            "Claude-Web",
            "ClaudeBot",
            "Cloudflare-AutoRAG",
            "CloudVertexBot",
            "cohere-ai",
            "cohere-training-data-crawler",
            "Cotoyogi",
            "Crawl4AI",
            "Crawlspace",
            "Datenbank/ Crawler",
            "DeepSeekBot",
            "Devin",
            "Diffbot",
            "DuckAssistBot",
            "Echobot/ Bot",
            "EchoboxBot",
            "FacebookBot",
            "facebookexternalhit",
            "Factset_spyderbot",
            "FirecrawlAgent",
            "FriendlyCrawler",
            "Gemini-Deep-Research",
            "Google-CloudVertexBot",
            "Google-Extended",
            "Google-Firebase",
            "Google-NotebookLM",
            "GoogleAgent-Mariner",
            "GoogleOther",
            "GoogleOther-Image",
            "GoogleOther-Video",
            "GPTBot",
            "iAskBot",
            "iaskspider",
            "iaskspider/2.0",
            "IbouBot",
            "ICC-Crawler",
            "ImagesiftBot",
            "imageSpider",
            "img2dataset",
            "ISSCyberRiskCrawler",
            "Kangaroo/ Bot",
            "KlaviyoAIBot",
            "KunatoCrawler",
            "laion-huggingface-processor",
            "LAIONDownloader",
            "LCC",
            "LinerBot",
            "Linguee/ Bot",
            "LinkupBot",
            "Manus-User",
            "meta-externalagent",
            "Meta-ExternalAgent",
            "meta-externalfetcher",
            "Meta-ExternalFetcher",
            "meta-webindexer",
            "MistralAI-User",
            "MistralAI-User/1.0",
            "MyCentralAIScraperBot",
            "netEstate/ Imprint/ Crawler",
            "NotebookLM",
            "NovaAct",
            "OAI-SearchBot",
            "omgili",
            "omgilibot",
            "OpenAI",
            "Operator",
            "PanguBot",
            "Panscient",
            "panscient.com",
            "Perplexity-User",
            "PerplexityBot",
            "PetalBot",
            "PhindBot",
            "Poggio-Citations",
            "Poseidon/ Research/ Crawler",
            "QualifiedBot",
            "QuillBot",
            "quillbot.com",
            "SBIntuitionsBot",
            "Scrapy",
            "SemrushBot-OCOB",
            "SemrushBot-SWA",
            "ShapBot",
            "Sidetrade/ indexer/ bot",
            "Spider",
            "TavilyBot",
            "TerraCotta",
            "Thinkbot",
            "TikTokSpider",
            "Timpibot",
            "TwinAgent",
            "VelenPublicWebCrawler",
            "WARDBot",
            "Webzio-Extended",
            "webzio-extended",
            "wpbot",
            "WRTNBot",
            "YaK",
            "YandexAdditional",
            "YandexAdditionalBot",
            "YouBot",
            "ZanistaBot",
        ]
    )
    return re.compile(pattern, re.IGNORECASE)


# this list is a little of a cross-mix of bots and a few browsers that
# can just skip the progressive checks (ala lynx). I've done this to
# just make the experience a little nicer
def socialBots():
    pattern = "(?:%s)" % "|".join(
        [
            "archive.org_bot",
            "W3C_Validator",
            "baiduspider",
            "bingbot",
            "embedly",
            "facebookexternalhit",
            "linkedinbot",
            "outbrain",
            "pinterest",
            "quora\ link\ preview",
            "rogerbot",
            "showyoubot",
            "slackbot",
            "twitterbot",
            "vkShare",
            "bingbot",
            "linkedinbot",
            "mediapartners-google",
            "mastodon",
            "ahrefsbot",
            "yandexbot",
            "msnbot",
            "BlueskyPreviewBot/1.0"
            # why googlebot? Because the static representation is 1-to-1 and
            # easier for even new M70+ GoogleBot to parse
            "googlebot",
            "google-structured-data-testing-tool",
            # just because it's cool
            "lynx",
            # web mentions handlers
            "webmention",
            "node-fetch",
            "guzzle",
            "bridgy",
            "go-http-client",
            "ruby",
            "appengine-google",
            "xray",
        ]
    )
    return re.compile(pattern, re.IGNORECASE)


# Compile once at import time, some save cycles
aiBots = aiBots()
socialBots = socialBots()
